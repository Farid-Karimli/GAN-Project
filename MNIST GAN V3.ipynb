{"cells":[{"cell_type":"markdown","metadata":{"id":"rF2x3qooyBTI"},"source":["# Deep Convolutional Generative Adversarial Network"]},{"cell_type":"markdown","metadata":{"id":"e1_Y75QXJS6h"},"source":["### Setup"]},{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":4733,"status":"ok","timestamp":1682779369979,"user":{"displayName":"Farid Karimli","userId":"15891063930443484555"},"user_tz":240},"id":"WZKbyU2-AiY-"},"outputs":[],"source":["import tensorflow as tf"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":36},"executionInfo":{"elapsed":6,"status":"ok","timestamp":1682779369980,"user":{"displayName":"Farid Karimli","userId":"15891063930443484555"},"user_tz":240},"id":"wx-zNbLqB4K8","outputId":"24388803-003a-4d34-fa5e-9263e13bf123"},"outputs":[{"data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'2.12.0'"]},"execution_count":2,"metadata":{},"output_type":"execute_result"}],"source":["tf.__version__"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":25950,"status":"ok","timestamp":1682779395926,"user":{"displayName":"Farid Karimli","userId":"15891063930443484555"},"user_tz":240},"id":"YzTlj4YdCip_","outputId":"3c51729d-568f-4333-f1a6-5d3334d32aac"},"outputs":[{"name":"stdout","output_type":"stream","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: imageio in /usr/local/lib/python3.10/dist-packages (2.25.1)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from imageio) (1.22.4)\n","Requirement already satisfied: pillow\u003e=8.3.2 in /usr/local/lib/python3.10/dist-packages (from imageio) (8.4.0)\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting git+https://github.com/tensorflow/docs\n","  Cloning https://github.com/tensorflow/docs to /tmp/pip-req-build-2o3vi74_\n","  Running command git clone --filter=blob:none --quiet https://github.com/tensorflow/docs /tmp/pip-req-build-2o3vi74_\n","  Resolved https://github.com/tensorflow/docs to commit abfbe6e54864baa38dbb985b984acd304be610d4\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting astor\n","  Downloading astor-0.8.1-py2.py3-none-any.whl (27 kB)\n","Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from tensorflow-docs==0.0.0.dev0) (1.4.0)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from tensorflow-docs==0.0.0.dev0) (3.1.2)\n","Requirement already satisfied: nbformat in /usr/local/lib/python3.10/dist-packages (from tensorflow-docs==0.0.0.dev0) (5.8.0)\n","Requirement already satisfied: protobuf\u003e=3.12 in /usr/local/lib/python3.10/dist-packages (from tensorflow-docs==0.0.0.dev0) (3.20.3)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from tensorflow-docs==0.0.0.dev0) (6.0)\n","Requirement already satisfied: MarkupSafe\u003e=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2-\u003etensorflow-docs==0.0.0.dev0) (2.1.2)\n","Requirement already satisfied: fastjsonschema in /usr/local/lib/python3.10/dist-packages (from nbformat-\u003etensorflow-docs==0.0.0.dev0) (2.16.3)\n","Requirement already satisfied: jupyter-core in /usr/local/lib/python3.10/dist-packages (from nbformat-\u003etensorflow-docs==0.0.0.dev0) (5.3.0)\n","Requirement already satisfied: traitlets\u003e=5.1 in /usr/local/lib/python3.10/dist-packages (from nbformat-\u003etensorflow-docs==0.0.0.dev0) (5.7.1)\n","Requirement already satisfied: jsonschema\u003e=2.6 in /usr/local/lib/python3.10/dist-packages (from nbformat-\u003etensorflow-docs==0.0.0.dev0) (4.3.3)\n","Requirement already satisfied: attrs\u003e=17.4.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema\u003e=2.6-\u003enbformat-\u003etensorflow-docs==0.0.0.dev0) (23.1.0)\n","Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,\u003e=0.14.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema\u003e=2.6-\u003enbformat-\u003etensorflow-docs==0.0.0.dev0) (0.19.3)\n","Requirement already satisfied: platformdirs\u003e=2.5 in /usr/local/lib/python3.10/dist-packages (from jupyter-core-\u003enbformat-\u003etensorflow-docs==0.0.0.dev0) (3.3.0)\n","Building wheels for collected packages: tensorflow-docs\n","  Building wheel for tensorflow-docs (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for tensorflow-docs: filename=tensorflow_docs-0.0.0.dev0-py3-none-any.whl size=183273 sha256=8e7df37f46b84941457feee1265a45c66a4d153631f6cfde86184e063916ff02\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-8c2qxd3g/wheels/86/0f/1e/3b62293c8ffd0fd5a49508e6871cdb7554abe9c62afd35ec53\n","Successfully built tensorflow-docs\n","Installing collected packages: astor, tensorflow-docs\n","Successfully installed astor-0.8.1 tensorflow-docs-0.0.0.dev0\n"]}],"source":["# To generate GIFs\n","!pip install imageio\n","!pip install git+https://github.com/tensorflow/docs"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":26,"status":"ok","timestamp":1682779395927,"user":{"displayName":"Farid Karimli","userId":"15891063930443484555"},"user_tz":240},"id":"YfIk2es3hJEd"},"outputs":[],"source":["import glob\n","import imageio\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import os\n","import PIL\n","from tensorflow.keras import layers\n","import time\n","\n","from IPython import display"]},{"cell_type":"markdown","metadata":{"id":"iYn4MdZnKCey"},"source":["### Load and prepare the dataset\n","\n","You will use the MNIST dataset to train the generator and the discriminator. The generator will generate handwritten digits resembling the MNIST data."]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2552,"status":"ok","timestamp":1682779398462,"user":{"displayName":"Farid Karimli","userId":"15891063930443484555"},"user_tz":240},"id":"a4fYMGxGhrna","outputId":"d9f20851-eab0-44ff-cfb5-52f360513640"},"outputs":[{"name":"stdout","output_type":"stream","text":["Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n","11490434/11490434 [==============================] - 2s 0us/step\n"]}],"source":["(train_images, train_labels), (_, _) = tf.keras.datasets.mnist.load_data()"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":7,"status":"ok","timestamp":1682779398462,"user":{"displayName":"Farid Karimli","userId":"15891063930443484555"},"user_tz":240},"id":"NFC2ghIdiZYE"},"outputs":[],"source":["train_images = train_images.reshape(train_images.shape[0], 28, 28, 1).astype('float32')\n","train_images = (train_images - 127.5) / 127.5  # Normalize the images to [-1, 1]"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7,"status":"ok","timestamp":1682779398463,"user":{"displayName":"Farid Karimli","userId":"15891063930443484555"},"user_tz":240},"id":"kaN18FDPVQ6J","outputId":"2d06e6ca-90bd-4cf0-de41-9e46ff97ca36"},"outputs":[{"data":{"text/plain":["(60000, 28, 28, 1)"]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["train_images.shape"]},{"cell_type":"code","execution_count":8,"metadata":{"executionInfo":{"elapsed":322,"status":"ok","timestamp":1682779398780,"user":{"displayName":"Farid Karimli","userId":"15891063930443484555"},"user_tz":240},"id":"S4PIDhoDLbsZ"},"outputs":[],"source":["BUFFER_SIZE = 60000\n","BATCH_SIZE = 256\n","NOISE_DIM = 200"]},{"cell_type":"code","execution_count":9,"metadata":{"executionInfo":{"elapsed":3044,"status":"ok","timestamp":1682779401823,"user":{"displayName":"Farid Karimli","userId":"15891063930443484555"},"user_tz":240},"id":"-yKCCQOoJ7cn"},"outputs":[],"source":["# Batch and shuffle the data\n","train_dataset = tf.data.Dataset.from_tensor_slices(train_images).shuffle(BUFFER_SIZE).batch(BATCH_SIZE)"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1682779401823,"user":{"displayName":"Farid Karimli","userId":"15891063930443484555"},"user_tz":240},"id":"8Ki6wzhKVKss","outputId":"9b1ba34b-b88b-46a3-f1c9-f688ba15588f"},"outputs":[{"data":{"text/plain":["\u003c_BatchDataset element_spec=TensorSpec(shape=(None, 28, 28, 1), dtype=tf.float32, name=None)\u003e"]},"execution_count":10,"metadata":{},"output_type":"execute_result"}],"source":["train_dataset"]},{"cell_type":"markdown","metadata":{"id":"THY-sZMiQ4UV"},"source":["## Create the models\n","\n","Both the generator and discriminator are defined using the [Keras Sequential API](https://www.tensorflow.org/guide/keras#sequential_model)."]},{"cell_type":"markdown","metadata":{"id":"-tEyxE-GMC48"},"source":["### The Generator\n","\n","The generator uses `tf.keras.layers.Conv2DTranspose` (upsampling) layers to produce an image from a seed (random noise). Start with a `Dense` layer that takes this seed as input, then upsample several times until you reach the desired image size of 28x28x1. Notice the `tf.keras.layers.LeakyReLU` activation for each layer, except the output layer which uses tanh."]},{"cell_type":"code","execution_count":11,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1682779401824,"user":{"displayName":"Farid Karimli","userId":"15891063930443484555"},"user_tz":240},"id":"6bpTcDqoLWjY"},"outputs":[],"source":["def make_generator_model():\n","    kernel_size = 4 # 4 instead of 5 in V2\n","\n","    model = tf.keras.Sequential()\n","    model.add(layers.Dense(7*7*256, use_bias=False, input_shape=(NOISE_DIM,)))\n","    model.add(layers.BatchNormalization())\n","    model.add(layers.ReLU())                                  # Change from LeakyReLU to ReLU\n","\n","    model.add(layers.Dense(7*7*256, use_bias=True))\n","    model.add(layers.BatchNormalization())\n","    model.add(layers.ReLU())\n","\n","    model.add(layers.Reshape((7, 7, 256)))\n","    assert model.output_shape == (None, 7, 7, 256)  # Note: None is the batch size\n","\n","    model.add(layers.Conv2DTranspose(128, (kernel_size, kernel_size), strides=(1, 1), padding='same', use_bias=False))\n","    assert model.output_shape == (None, 7, 7, 128)\n","    model.add(layers.BatchNormalization())\n","    model.add(layers.ReLU())\n","\n","    model.add(layers.Conv2DTranspose(64, (kernel_size, kernel_size), strides=(2, 2), padding='same', use_bias=False))\n","    assert model.output_shape == (None, 14, 14, 64)\n","    model.add(layers.BatchNormalization())\n","    model.add(layers.ReLU())\n","\n","    model.add(layers.Conv2DTranspose(1, (kernel_size, kernel_size), strides=(2, 2), padding='same', use_bias=False, activation='sigmoid')) # Sigmoid instead of tanh\n","    assert model.output_shape == (None, 28, 28, 1)\n","\n","    return model\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"GyWgG09LCSJl"},"source":["Use the (as yet untrained) generator to create an image."]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":448},"executionInfo":{"elapsed":10147,"status":"ok","timestamp":1682779411968,"user":{"displayName":"Farid Karimli","userId":"15891063930443484555"},"user_tz":240},"id":"gl7jcC7TdPTG","outputId":"775cc0c3-e792-402a-f8b9-d9d987e37699"},"outputs":[{"data":{"text/plain":["\u003cmatplotlib.image.AxesImage at 0x7f1a082d2b30\u003e"]},"execution_count":12,"metadata":{},"output_type":"execute_result"},{"data":{"image/png":"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\n","text/plain":["\u003cFigure size 640x480 with 1 Axes\u003e"]},"metadata":{},"output_type":"display_data"}],"source":["generator = make_generator_model()\n","\n","noise = tf.random.normal([1, NOISE_DIM])\n","generated_image = generator(noise, training=False)\n","\n","plt.imshow(generated_image[0, :, :, 0], cmap='gray')"]},{"cell_type":"code","execution_count":13,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":537,"status":"ok","timestamp":1682779412479,"user":{"displayName":"Farid Karimli","userId":"15891063930443484555"},"user_tz":240},"id":"LE-uliGOVFrf","outputId":"777ec9fa-fb86-47dc-ad71-b72c40b6cb64"},"outputs":[{"name":"stdout","output_type":"stream","text":["Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense (Dense)               (None, 12544)             2508800   \n","                                                                 \n"," batch_normalization (BatchN  (None, 12544)            50176     \n"," ormalization)                                                   \n","                                                                 \n"," re_lu (ReLU)                (None, 12544)             0         \n","                                                                 \n"," dense_1 (Dense)             (None, 12544)             157364480 \n","                                                                 \n"," batch_normalization_1 (Batc  (None, 12544)            50176     \n"," hNormalization)                                                 \n","                                                                 \n"," re_lu_1 (ReLU)              (None, 12544)             0         \n","                                                                 \n"," reshape (Reshape)           (None, 7, 7, 256)         0         \n","                                                                 \n"," conv2d_transpose (Conv2DTra  (None, 7, 7, 128)        524288    \n"," nspose)                                                         \n","                                                                 \n"," batch_normalization_2 (Batc  (None, 7, 7, 128)        512       \n"," hNormalization)                                                 \n","                                                                 \n"," re_lu_2 (ReLU)              (None, 7, 7, 128)         0         \n","                                                                 \n"," conv2d_transpose_1 (Conv2DT  (None, 14, 14, 64)       131072    \n"," ranspose)                                                       \n","                                                                 \n"," batch_normalization_3 (Batc  (None, 14, 14, 64)       256       \n"," hNormalization)                                                 \n","                                                                 \n"," re_lu_3 (ReLU)              (None, 14, 14, 64)        0         \n","                                                                 \n"," conv2d_transpose_2 (Conv2DT  (None, 28, 28, 1)        1024      \n"," ranspose)                                                       \n","                                                                 \n","=================================================================\n","Total params: 160,630,784\n","Trainable params: 160,580,224\n","Non-trainable params: 50,560\n","_________________________________________________________________\n"]}],"source":["generator.summary()"]},{"cell_type":"markdown","metadata":{"id":"D0IKnaCtg6WE"},"source":["### The Discriminator\n","\n","The discriminator is a CNN-based image classifier."]},{"cell_type":"code","execution_count":14,"metadata":{"executionInfo":{"elapsed":11,"status":"ok","timestamp":1682779412479,"user":{"displayName":"Farid Karimli","userId":"15891063930443484555"},"user_tz":240},"id":"dw2tPLmk2pEP"},"outputs":[],"source":["def make_discriminator_model(version=1):\n","    model = tf.keras.Sequential()\n","\n","    if version == 2:\n","        model.add(layers.Conv2D(32, (5, 5), strides=(1, 1), padding='same', input_shape=[28, 28, 1]))\n","        model.add(layers.LeakyReLU())\n","        model.add(layers.Dropout(0.3))\n","        model.add(layers.Conv2D(64, (5, 5), strides=(2, 2), padding='same'))\n","\n","    else:\n","          model.add(layers.Conv2D(64, (5, 5), strides=(2, 2), padding='same', input_shape=[28, 28, 1]))\n","\n","\n","    model.add(layers.LeakyReLU())\n","    model.add(layers.Dropout(0.3))\n","\n","    model.add(layers.Conv2D(128, (5, 5), strides=(2, 2), padding='same'))\n","    model.add(layers.LeakyReLU())\n","    model.add(layers.Dropout(0.3))\n","\n","    model.add(layers.Flatten())\n","    model.add(layers.Dense(1))\n","\n","    return model"]},{"cell_type":"markdown","metadata":{"id":"QhPneagzCaQv"},"source":["Use the (as yet untrained) discriminator to classify the generated images as real or fake. The model will be trained to output positive values for real images, and negative values for fake images."]},{"cell_type":"code","execution_count":15,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8,"status":"ok","timestamp":1682779412479,"user":{"displayName":"Farid Karimli","userId":"15891063930443484555"},"user_tz":240},"id":"gDkA05NE6QMs","outputId":"b677d644-e381-47d2-f803-1b1041ec45b2"},"outputs":[{"name":"stdout","output_type":"stream","text":["tf.Tensor([[0.01102741]], shape=(1, 1), dtype=float32)\n"]}],"source":["discriminator = make_discriminator_model(2)\n","decision = discriminator(generated_image)\n","print (decision)"]},{"cell_type":"markdown","metadata":{"id":"0FMYgY_mPfTi"},"source":["## Define the loss and optimizers\n","\n","Define loss functions and optimizers for both models.\n"]},{"cell_type":"code","execution_count":16,"metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1682779412480,"user":{"displayName":"Farid Karimli","userId":"15891063930443484555"},"user_tz":240},"id":"psQfmXxYKU3X"},"outputs":[],"source":["# This method returns a helper function to compute cross entropy loss\n","cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)"]},{"cell_type":"markdown","metadata":{"id":"PKY_iPSPNWoj"},"source":["### Discriminator loss\n","\n","This method quantifies how well the discriminator is able to distinguish real images from fakes. It compares the discriminator's predictions on real images to an array of 1s, and the discriminator's predictions on fake (generated) images to an array of 0s."]},{"cell_type":"code","execution_count":17,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1682779412480,"user":{"displayName":"Farid Karimli","userId":"15891063930443484555"},"user_tz":240},"id":"wkMNfBWlT-PV"},"outputs":[],"source":["def discriminator_loss(real_output, fake_output):\n","    real_loss = cross_entropy(tf.ones_like(real_output), real_output)\n","    fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)\n","    total_loss = real_loss + fake_loss\n","    return total_loss"]},{"cell_type":"markdown","metadata":{"id":"Jd-3GCUEiKtv"},"source":["### Generator loss\n","The generator's loss quantifies how well it was able to trick the discriminator. Intuitively, if the generator is performing well, the discriminator will classify the fake images as real (or 1). Here, compare the discriminators decisions on the generated images to an array of 1s."]},{"cell_type":"code","execution_count":18,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1682779412480,"user":{"displayName":"Farid Karimli","userId":"15891063930443484555"},"user_tz":240},"id":"90BIcCKcDMxz"},"outputs":[],"source":["def generator_loss(fake_output):\n","    return cross_entropy(tf.ones_like(fake_output), fake_output)"]},{"cell_type":"code","execution_count":19,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1682779412480,"user":{"displayName":"Farid Karimli","userId":"15891063930443484555"},"user_tz":240},"id":"iWCn_PVdEJZ7"},"outputs":[],"source":["generator_optimizer = tf.keras.optimizers.Adam(1e-4)\n","discriminator_optimizer = tf.keras.optimizers.Adam(1e-4)"]},{"cell_type":"markdown","metadata":{"id":"mWtinsGDPJlV"},"source":["### Save checkpoints\n","This notebook also demonstrates how to save and restore models, which can be helpful in case a long running training task is interrupted."]},{"cell_type":"code","execution_count":20,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1682779412481,"user":{"displayName":"Farid Karimli","userId":"15891063930443484555"},"user_tz":240},"id":"CA1w-7s2POEy"},"outputs":[],"source":["checkpoint_dir = './training_checkpoints'\n","checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n","checkpoint = tf.train.Checkpoint(generator_optimizer=generator_optimizer,\n","                                 discriminator_optimizer=discriminator_optimizer,\n","                                 generator=generator,\n","                                 discriminator=discriminator)"]},{"cell_type":"markdown","metadata":{"id":"Rw1fkAczTQYh"},"source":["## Define the training loop\n"]},{"cell_type":"code","execution_count":21,"metadata":{"executionInfo":{"elapsed":592,"status":"ok","timestamp":1682779413068,"user":{"displayName":"Farid Karimli","userId":"15891063930443484555"},"user_tz":240},"id":"NS2GWywBbAWo"},"outputs":[],"source":["EPOCHS = 100\n","noise_dim = NOISE_DIM\n","num_examples_to_generate = 12\n","\n","# For reproducibility\n","# to visualize progress in the animated GIF)\n","seed = tf.random.normal([num_examples_to_generate, noise_dim])"]},{"cell_type":"markdown","metadata":{"id":"jylSonrqSWfi"},"source":["The training loop begins with generator receiving a random seed as input. That seed is used to produce an image. The discriminator is then used to classify real images (drawn from the training set) and fakes images (produced by the generator). The loss is calculated for each of these models, and the gradients are used to update the generator and discriminator."]},{"cell_type":"code","execution_count":22,"metadata":{"executionInfo":{"elapsed":11,"status":"ok","timestamp":1682779413070,"user":{"displayName":"Farid Karimli","userId":"15891063930443484555"},"user_tz":240},"id":"3t5ibNo05jCB"},"outputs":[],"source":["# Notice the use of `tf.function`\n","# This annotation causes the function to be \"compiled\".\n","@tf.function\n","def train_step(images):\n","    noise = tf.random.normal([BATCH_SIZE, noise_dim])\n","\n","    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n","      generated_images = generator(noise, training=True)\n","\n","      real_output = discriminator(images, training=True)\n","      fake_output = discriminator(generated_images, training=True)\n","\n","      gen_loss = generator_loss(fake_output)\n","      disc_loss = discriminator_loss(real_output, fake_output)\n","\n","    gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n","    gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n","\n","    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n","    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))\n","\n","    #return {'gen_loss': gen_loss, 'disc_loss': disc_loss}"]},{"cell_type":"code","execution_count":23,"metadata":{"executionInfo":{"elapsed":11,"status":"ok","timestamp":1682779413071,"user":{"displayName":"Farid Karimli","userId":"15891063930443484555"},"user_tz":240},"id":"2M7LmLtGEMQJ"},"outputs":[],"source":["def train(dataset, epochs, version=1):\n","\n","  for epoch in range(epochs):\n","    start = time.time()\n","\n","    for image_batch in dataset:\n","      train_step(image_batch)\n","\n","    # Produce images for the GIF as you go\n","    display.clear_output(wait=True)\n","    generate_and_save_images(generator,epoch + 1, seed)\n","\n","    # Save the model every 15 epochs\n","    if (epoch + 1) % 15 == 0:\n","      checkpoint.save(file_prefix = checkpoint_prefix)\n","\n","    print ('Time for epoch {} is {} sec'.format(epoch + 1, time.time()-start))\n","\n","  # Generate after the final epoch\n","  display.clear_output(wait=True)\n","  generate_and_save_images(generator,\n","                           epochs,\n","                           seed, version)\n","  \n","\n"]},{"cell_type":"markdown","metadata":{"id":"2aFF7Hk3XdeW"},"source":["**Generate and save images**\n"]},{"cell_type":"code","execution_count":24,"metadata":{"executionInfo":{"elapsed":10,"status":"ok","timestamp":1682779413071,"user":{"displayName":"Farid Karimli","userId":"15891063930443484555"},"user_tz":240},"id":"RmdVsmvhPxyy"},"outputs":[],"source":["def generate_and_save_images(model, epoch, test_input):\n","  # Notice `training` is set to False.\n","  # This is so all layers run in inference mode (batchnorm).\n","  predictions = model(test_input, training=False)\n","\n","  fig = plt.figure(figsize=(4, 4))\n","  #fig.suptitle(f\"Model version {version} output after training for {epoch} epochs\")\n","  for i in range(predictions.shape[0]):\n","      plt.subplot(4, 4, i+1)\n","      plt.imshow(predictions[i, :, :, 0] * 127.5 + 127.5, cmap='gray')\n","      plt.axis('off')\n","\n","  plt.show()"]},{"cell_type":"markdown","metadata":{"id":"dZrd4CdjR-Fp"},"source":["## Train the model\n","Call the `train()` method defined above to train the generator and discriminator simultaneously. Note, training GANs can be tricky. It's important that the generator and discriminator do not overpower each other (e.g., that they train at a similar rate).\n","\n","At the beginning of the training, the generated images look like random noise. As training progresses, the generated digits will look increasingly real. After about 50 epochs, they resemble MNIST digits. This may take about one minute / epoch with the default settings on Colab."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/","height":282},"id":"Ly3UN0SLLY2l"},"outputs":[{"data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAUkAAAD3CAYAAACQPaYZAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAFGElEQVR4nO3dUU7y3AKG0XLiwDqJOh3KdGASzGyfOz8S/zwpVAPqWgkJF4Rs3uAjXFgPY4wxAfCf/vfsAwC8MpEECCIJEEQSIIgkQBBJgCCSAEEkAcq407IsY5qmP3dblmWcz+dxPp/vneyTdV2f/nqecZvneazrOtZ1taENf8yGPkkChLetD3x/f//Oc7y8y+XycX9Zloee43Q6TdM0Tdfr9SuO9OPcvu7j8fjQc9jw+nHfho+5d8PDGNv+dvtwODx8qN9m42Sf2PAfG+5nw/22bOjrNkAQSYAgkgBBJAGCSAIEkQQIIgkQRBIgiCRAEEmAIJIAQSQBgkgCBJEECCIJEEQSIIgkQBBJgCCSAEEkAYJIAgSRBAgiCRBEEiCIJEAQSYAgkgBBJAGCSAIEkQQIIgkQRBIgiCRAEEmAIJIAQSQBgkgCBJEECCIJEEQSIIgkQBBJgCCSAEEkAYJIAgSRBAgiCRBEEiCIJEAQSYAgkgBBJAGCSAIEkQQIIgkQRBIgiCRAEEmAIJIAQSQBwuZILssyLcvynWf59eZ5nuZ5fvYxfjQb7mfD+7xtfeBtIC+Xy7cc5tXt/SVx+8a8Xq/7DvND7f3htKENv8I9G/q6DRAOY4zx7EMAvCqfJAGCSAIEkQQIIgkQRBIgiCRAEEmAIJIAQSQBgkgCBJEECCIJEEQSoIw7res6pmn6c7d5nse6rmNd13sns6ENX3LDZVme/nqecVuWZZzP53E+nzft5JMkQNh8ZfLT6TRN09+9kvHt6z4ejw89hw2vH/dt+Jiv2PD9/f2LTvMz3f5nhS3/bWDzRXcPh8Pjp/plNk72iQ3/seF+Ntxvy4a+bgMEkQQIIgkQRBIgiCRAEEmAIJIAQSQBgkgCBJEECCIJEEQSIIgkQBBJgCCSAEEkAYJIAgSRBAgiCRBEEiCIJEAQSYAgkgBBJAGCSAIEkQQIIgkQRBIgiCRAEEmAIJIAQSQBgkgCBJEECCIJEEQSIIgkQBBJgCCSAEEkAYJIAgSRBAgiCRBEEiCIJEAQSYAgkgBBJAGCSAIEkQQIIgkQRBIgiCRAEEmAIJIAQSQBgkgCBJEECCIJEEQSIGyO5DzP0zzP33iU38+G+9lwv2VZpmVZnn2MH+Nt6wNv35jX6/UbjvL69v5w2tCGX2HvhreBvFwuO0/zM93zS8LXbYBwGGOMZx8C4FX5JAkQRBIgiCRAEEmAIJIAQSQBgkgCBJEECCIJEEQSIIgkQBBJgDLutK7rmKbpz93meR7ruo51Xe+dzIY2tOEL3e7d0CdJgLD5orun02mapr97odPb1308Hh96DhteP+7b8DE23O/eDTdfT/JwODx8qN9m42Sf2PAfG+5nw/22bOjrNkAQSYAgkgBBJAGCSAIEkQQIIgkQRBIgiCRAEEmAIJIAQSQBgkgCBJEECCIJEEQSIIgkQBBJgCCSAEEkAYJIAgSRBAgiCRBEEiCIJEAQSYAgkgBBJAGCSAIEkQQIIgkQRBIgiCRAEEmAIJIAQSQBgkgCBJEECCIJEEQSIIgkQBBJgCCSAEEkAYJIAgSRBAgiCRBEEiCIJEAQSYAgkgBBJAGCSAIEkQQIIgkQRBIgiCRAEEmAIJIAQSQBwuZIzvM8zfP8jUf5/Wy4nw33s+F93rY+8HbU6/X6DUd5fXvfWDa04Vew4X73bOjrNkA4jDHGsw8B8Kp8kgQIIgkQRBIgiCRAEEmAIJIAQSQBgkgCBJEECP8Hqq5X5ZCg7VYAAAAASUVORK5CYII=\n","text/plain":["\u003cFigure size 400x400 with 12 Axes\u003e"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Time for epoch 100 is 34.0726273059845 sec\n"]},{"ename":"TypeError","evalue":"ignored","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m\u003cipython-input-25-d152560ca122\u003e\u001b[0m in \u001b[0;36m\u003ccell line: 1\u003e\u001b[0;34m()\u001b[0m\n\u001b[0;32m----\u003e 1\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEPOCHS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m\u003cipython-input-23-affb6f593890\u003e\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(dataset, epochs, version)\u001b[0m\n\u001b[1;32m     19\u001b[0m   \u001b[0;31m# Generate after the final epoch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m   \u001b[0mdisplay\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclear_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---\u003e 21\u001b[0;31m   generate_and_save_images(generator,\n\u001b[0m\u001b[1;32m     22\u001b[0m                            \u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m                            seed, version)\n","\u001b[0;31mTypeError\u001b[0m: generate_and_save_images() takes 3 positional arguments but 4 were given"]}],"source":["train(train_dataset, EPOCHS)"]},{"cell_type":"markdown","metadata":{"id":"rfM4YcPVPkNO"},"source":["Restore the latest checkpoint."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"XhXsd0srPo8c"},"outputs":[],"source":["checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))"]},{"cell_type":"markdown","metadata":{"id":"P4M_vIbUi7c0"},"source":["## Create a GIF\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"WfO5wCdclHGL"},"outputs":[],"source":["# Display a single image using the epoch number\n","def display_image(epoch_no):\n","  return PIL.Image.open('image_at_epoch_{:04d}.png'.format(epoch_no))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"5x3q9_Oe5q0A"},"outputs":[],"source":["display_image(EPOCHS)"]},{"cell_type":"markdown","metadata":{"id":"NywiH3nL8guF"},"source":["Use `imageio` to create an animated gif using the images saved during training."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"IGKQgENQ8lEI"},"outputs":[],"source":["anim_file = 'dcgan.gif'\n","\n","with imageio.get_writer(anim_file, mode='I') as writer:\n","  filenames = glob.glob('image*.png')\n","  filenames = sorted(filenames)\n","  for filename in filenames:\n","    image = imageio.imread(filename)\n","    writer.append_data(image)\n","  image = imageio.imread(filename)\n","  writer.append_data(image)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"ZBwyU6t2Wf3g"},"outputs":[],"source":["import tensorflow_docs.vis.embed as embed\n","embed.embed_file(anim_file)"]}],"metadata":{"accelerator":"GPU","colab":{"machine_shape":"hm","name":"","provenance":[{"file_id":"https://github.com/tensorflow/docs/blob/master/site/en/tutorials/generative/dcgan.ipynb","timestamp":1680712166047}],"version":""},"gpuClass":"premium","kernelspec":{"display_name":"Python 3","name":"python3"}},"nbformat":4,"nbformat_minor":0}